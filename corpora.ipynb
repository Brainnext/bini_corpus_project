{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab1667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "from pathlib import Path\n",
    "import wordninja\n",
    "import csv\n",
    "import re\n",
    "\n",
    "bini = Path(\"/home/kinged/codes/dala/group_a/bini_dict.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6f7b4",
   "metadata": {},
   "source": [
    "the bini dictionary starts from page 18 down to page 251 for all the word and translations used to form the coropra, the latter pages may contain some other useful information that can be used in some manner to help in translations and effective corpora development "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed274425",
   "metadata": {},
   "outputs": [],
   "source": [
    "page = r\"/home/kinged/codes/dala/group_a/bini_dict.pdf\"\n",
    "path = r\"/home/kinged/codes/dala/group_a/text\"\n",
    "\n",
    "# function to extract the pages from the pdfs\n",
    "\n",
    "def extract_texts(file_path: str, dest_path: str):\n",
    "    \"\"\"\n",
    "    **extract the pages from the pdf and store them as text files inside a specified directory**\n",
    "    \n",
    "    Args:\n",
    "        file_path(str): path to pdf file\n",
    "        dest_path(str): path to the destination folder\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    page = PdfReader(Path(file_path))\n",
    "    path = Path(dest_path)\n",
    "    if path.exists() == True:\n",
    "        pass\n",
    "    else:\n",
    "        path.mkdir()\n",
    "\n",
    "    for x in range(18, page.get_num_pages()):\n",
    "        with open(f\"{path}/pages{x}.txt\", \"w\") as f:\n",
    "            f.write(page.pages[x].extract_text())\n",
    "\n",
    "extract_texts(page, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4d79ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for transforming the files\n",
    "\n",
    "texts = Path(\"/home/kinged/codes/dala/group_a/text\")\n",
    "cleaned_dir = Path(\"/home/kinged/codes/dala/group_a/cleaned_text\")\n",
    "cleaned_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove special annotation symbols (e.g., [.*], [..], etc.)\n",
    "    text = re.sub(r'\\[[^\\]]*\\]', '', text)\n",
    "    # Replace line breaks within words with a space\n",
    "    text = re.sub(r'([a-zA-Z0-9])\\n([a-zA-Z0-9])', r'\\1 \\2', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Attempt to split merged words using wordninja\n",
    "    words = []\n",
    "    for token in text.split():\n",
    "        if len(token) > 15:  # likely merged\n",
    "            words.extend(wordninja.split(token))\n",
    "        else:\n",
    "            words.append(token)\n",
    "    return ' '.join(words)\n",
    "\n",
    "def clean_texts_in_folder(folder_path, output_folder):\n",
    "    for fpath in folder_path.glob('*.txt'):\n",
    "        with open(fpath, 'r', encoding='utf-8') as f:\n",
    "            raw = f.read()\n",
    "        cleaned = clean_text(raw)\n",
    "        out_path = output_folder / fpath.name.replace('.txt', '_cleaned.txt')\n",
    "        with open(out_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(cleaned)\n",
    "\n",
    "# Run cleaning on all text files in the folder\n",
    "clean_texts_in_folder(texts, cleaned_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "290d918c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_corpus_csv\u001b[39m(cleaned_folder, output_csv):\n\u001b[32m      4\u001b[39m     corpus = []\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_corpus_csv(cleaned_folder, output_csv):\n",
    "    corpus = []\n",
    "    for fpath in Path(cleaned_folder).glob('*_cleaned.txt'):\n",
    "        with open(fpath, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            # Split entries by semicolon or newline, strip whitespace\n",
    "            entries = [entry.strip() for entry in re.split(r'[;\\n]', text) if entry.strip()]\n",
    "            for entry in entries:\n",
    "                corpus.append({'text': entry, 'source_file': fpath.name})\n",
    "    df = pd.DataFrame(corpus)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Create corpus CSV from cleaned data\n",
    "create_corpus_csv('/home/kinged/codes/dala/group_a/cleaned_text', '/home/kinged/codes/dala/group_a/corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2202f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
