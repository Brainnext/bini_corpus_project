{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5ab1667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abokpoi[\"J(i)\"woof\"made\n",
      "ofwood,'usedinweaving\n",
      ";\n",
      "strikesthethreadsdowninordertofastenthem.(2)astickheldbywomenataburialorsecondburial,representingamatchet;itissupposedtokeep\n",
      "evilspiritsawayfromthedeceased'schildren.abokpo2['*.]atree,Diospyros\n",
      "crassiflora,usedinbuildinghousesandalso(bytheJskriandIjopeople)forpaddles(abokpo1isnotmadefrom\n",
      "it).\n",
      "abutete[.'..](high)edgeofaroad\n",
      ";\n",
      "v.aze[.'].\n",
      "ada[\"]state-sword,wornbytheDba,somebigchiefs,andthepriestsofOsa[..]andOxwahs\n",
      "[J.Y,of.Yor.ada[./].ada[/]family-representativesat\n",
      "aburial.ada[..]junction;crossroads.Adabi\"'[.).]adeitysupposedtostandontheboundarybetweentheworldandsfioi[.'.],onAd-agb-ad-sfim[.'.'•.]:therethedeadpeoplerestawhile.AnAdabiisalsomadeandwor-shippedbythepriestessesof\n",
      "Oloka[\"•];cfada[..].adeke[. ]femaleofosels[.](?);\n",
      "itcarriesmanyeggs;lookslike\n",
      "themaleogoro[..'],buthasshiningstripes;cfeks[.\"%].\n",
      "adese[*\n",
      "](1)middle;ades-ot-\n",
      "oye['X']{tisinthemiddle\n",
      "(ofit);ades-uhuou[.*.'.]crown\n",
      "ofhead.(2)adessn-eva\n",
      "[/J\"themiddleoftwo\":be-tween;ysl-adessn-ev-ifa(la[])\n",
      "[•*•]don'tpassbetweenthem!'(3)adessn-eva:\"intwo\";nawe1-adesen-eva\n",
      "[';jcutitintwo!\n",
      "ads['*]apointedstickforpicking\n",
      "fruitofftrees,ade['.]buyer;cfde['].\n",
      "ads[]placenta,adiys'[*/]fowl;aYorubawordmoreusedthanoxoxo[.'.]atpresent;cfYor.adie[•.•]•\n",
      "adows[.\"%.]amanwhowalkson\n",
      "tip-toeonaccountofsorefeet.\n",
      "Adolo[''\n",
      "]nameofanOba,fatherofDbaOvofaos[/..];hisaltar\n",
      "isshownonL.R.fig.84.adolobie[./*]rebirth,beingbornagain(Akugbe);cfdolo[/],bie\n",
      "[']•adoloko[*\".]sword;sabre;cfJeknudoloko['J.ana['](1)chisel;yegi-afiafia\n",
      "i3-obo[*..*..*]don'tletthechisel\n",
      "cutmy'hand!(2)aninsectaffectingtheyam-creepers;cfna['].\n",
      "afiagbe['*](Christian)blessing(Akugbe);cffi£[*]\n",
      ".\n",
      "afialaflag.\n",
      "afiama[..]pulse;afiamafiav>s\n",
      "teiteiL../\"]mYheart. is\n",
      "beating(withfear);cffia['].\n",
      "afiano(5a[\"*'.]imitationcoralbeads;originalmeaningis\"onedoesnotcutforsomebody\",butthereasonforthisnameis\n",
      "notclear,afierha[...]\"wood-cutting\":headache.aforho['\n",
      "]agameinwhichsome-\n",
      "thing,\"preferablysomethinged-\n",
      "ible,isthrownontheground,whereuponeverybodytriesto\n",
      "seizeasmuchofitashecan.afo[\"]apurificationmedicineandsoupsaidtobecomposed\n",
      "of43differentherbs;cf.io\n",
      "v.ebe[/].aga[\"]achair(withrest);ag-ika\n",
      "[\"Jcane-chair;cfYor.aga[,•]\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import wordninja\n",
    "from pypdf import PdfReader\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "dir_path = Path()\n",
    "bini = dir_path/\"bini_dict.pdf\"\n",
    "\n",
    "pdf = PdfReader(bini)\n",
    "pdf_19 = pdf.pages[19].extract_text()\n",
    "print(pdf_19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa6f7b4",
   "metadata": {},
   "source": [
    "the bini dictionary starts from page 18 down to page 251 for all the word and translations used to form the coropra, the latter pages may contain some other useful information that can be used in some manner to help in translations and effective corpora development "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed274425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(start: int, file, folder):\n",
    "    \"\"\"\n",
    "    **writes all pages of the pdf into a single text file**\n",
    "    \"\"\"\n",
    "    file_path = Path(file)\n",
    "    doc = PdfReader(file_path)\n",
    "    folder_path = Path(folder)\n",
    "\n",
    "    if folder_path.exists():\n",
    "        pass\n",
    "    else:\n",
    "        folder_path.mkdir()\n",
    "\n",
    "    with open(f\"{folder_path}/raw.txt\", \"w\") as f:\n",
    "        for page in range(start, doc.get_num_pages()):\n",
    "            f.write(doc.pages[page].extract_text(extraction_mode='plain')) # chnage the extraction_mode argument to layout for different extraction, makes it harder to clean imo\n",
    "        \n",
    "    \n",
    "file = dir_path/\"bini_dict.pdf\"\n",
    "folder = dir_path/\"raw\"\n",
    "read_text(start=18, file=file, folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da87754",
   "metadata": {},
   "source": [
    "regex rules:\n",
    "- extract only words and symbols/punctuation marks in the the txt file\n",
    "-  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4869f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4d79ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for transforming the files\n",
    "\n",
    "texts = Path()/\"raw/raw.txt\"\n",
    "cleaned_dir = Path(\"/home/kinged/codes/dala/group_a/cleaned_text\")\n",
    "cleaned_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove special annotation symbols (e.g., [.*], [..], etc.)\n",
    "    text = re.sub(r'\\[[^\\]]*\\]', '', text)\n",
    "    # Replace line breaks within words with a space\n",
    "    text = re.sub(r'([a-zA-Z0-9])\\n([a-zA-Z0-9])', r'\\1 \\2', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Attempt to split merged words using wordninja\n",
    "    words = []\n",
    "    for token in text.split():\n",
    "        if len(token) > 15:  # likely merged\n",
    "            words.extend(wordninja.split(token))\n",
    "        else:\n",
    "            words.append(token)\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Clean a single file\n",
    "with open(texts, 'r', encoding='utf-8') as f:\n",
    "    raw = f.read()\n",
    "cleaned = clean_text(raw)\n",
    "out_path = cleaned_dir / texts.name.replace('.txt', '_cleaned.txt')\n",
    "with open(out_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(cleaned)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7803cb38",
   "metadata": {},
   "source": [
    "code generated for cleaning a specific type of cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73c9d66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning done. Output saved to bini_cleaned.txt.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_bini_dictionary(raw_text):\n",
    "    # Split the text into lines\n",
    "    lines = raw_text.strip().split('\\n')\n",
    "\n",
    "    cleaned_entries = []\n",
    "    entry = \"\"\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        # If a line starts with a lowercase word followed by some symbol (likely a new entry)\n",
    "        if re.match(r\"^[a-zA-Z]+\\s?[\\[\\(']\", line):\n",
    "            # Save the previous entry if exists\n",
    "            if entry:\n",
    "                cleaned_entries.append(entry.strip())\n",
    "                entry = \"\"\n",
    "\n",
    "            # Start new entry\n",
    "            parts = re.split(r'\\s*[\\[\\(].*?\\]\\s*', line, maxsplit=1)\n",
    "            if len(parts) >= 2:\n",
    "                bini_word = parts[0].strip()\n",
    "                definition = parts[1].strip()\n",
    "                entry = f\"{bini_word} – {definition}\"\n",
    "            else:\n",
    "                entry = line  # fallback if format is unexpected\n",
    "        else:\n",
    "            # Append continuation lines\n",
    "            entry += \" \" + line.strip()\n",
    "\n",
    "    # Add the last entry\n",
    "    if entry:\n",
    "        cleaned_entries.append(entry.strip())\n",
    "\n",
    "    return '\\n\\n'.join(cleaned_entries)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "with open('raw/raw.txt', 'r', encoding='utf-8') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "cleaned_text = clean_bini_dictionary(raw_text)\n",
    "\n",
    "with open('bini_cleaned.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(cleaned_text)\n",
    "\n",
    "print(\"Cleaning done. Output saved to bini_cleaned.txt.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.13.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
